{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xRomory/CCADMACL_PROJECT_COM231ML/blob/main/finals_advanced_machine_leaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqnEqUqb9eVD",
        "outputId": "7470e420-019b-4021-e0ad-01a812e6a9ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /home/romory/.cache/kagglehub/datasets/arjunbhasin2013/ccdata/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"arjunbhasin2013/ccdata\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "tY9kuSJchB5I",
        "outputId": "009753a6-792f-4364-8c7b-bb74b30f570d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files in dataset directory: ['CC GENERAL.csv']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CUST_ID</th>\n",
              "      <th>BALANCE</th>\n",
              "      <th>BALANCE_FREQUENCY</th>\n",
              "      <th>PURCHASES</th>\n",
              "      <th>ONEOFF_PURCHASES</th>\n",
              "      <th>INSTALLMENTS_PURCHASES</th>\n",
              "      <th>CASH_ADVANCE</th>\n",
              "      <th>PURCHASES_FREQUENCY</th>\n",
              "      <th>ONEOFF_PURCHASES_FREQUENCY</th>\n",
              "      <th>PURCHASES_INSTALLMENTS_FREQUENCY</th>\n",
              "      <th>CASH_ADVANCE_FREQUENCY</th>\n",
              "      <th>CASH_ADVANCE_TRX</th>\n",
              "      <th>PURCHASES_TRX</th>\n",
              "      <th>CREDIT_LIMIT</th>\n",
              "      <th>PAYMENTS</th>\n",
              "      <th>MINIMUM_PAYMENTS</th>\n",
              "      <th>PRC_FULL_PAYMENT</th>\n",
              "      <th>TENURE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C10001</td>\n",
              "      <td>40.900749</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>95.40</td>\n",
              "      <td>0.00</td>\n",
              "      <td>95.4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>201.802084</td>\n",
              "      <td>139.509787</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C10002</td>\n",
              "      <td>3202.467416</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6442.945483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>7000.0</td>\n",
              "      <td>4103.032597</td>\n",
              "      <td>1072.340217</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C10003</td>\n",
              "      <td>2495.148862</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>773.17</td>\n",
              "      <td>773.17</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>622.066742</td>\n",
              "      <td>627.284787</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C10004</td>\n",
              "      <td>1666.670542</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>1499.00</td>\n",
              "      <td>1499.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>205.788017</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C10005</td>\n",
              "      <td>817.714335</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.00</td>\n",
              "      <td>16.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>678.334763</td>\n",
              "      <td>244.791237</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  CUST_ID      BALANCE  BALANCE_FREQUENCY  PURCHASES  ONEOFF_PURCHASES  \\\n",
              "0  C10001    40.900749           0.818182      95.40              0.00   \n",
              "1  C10002  3202.467416           0.909091       0.00              0.00   \n",
              "2  C10003  2495.148862           1.000000     773.17            773.17   \n",
              "3  C10004  1666.670542           0.636364    1499.00           1499.00   \n",
              "4  C10005   817.714335           1.000000      16.00             16.00   \n",
              "\n",
              "   INSTALLMENTS_PURCHASES  CASH_ADVANCE  PURCHASES_FREQUENCY  \\\n",
              "0                    95.4      0.000000             0.166667   \n",
              "1                     0.0   6442.945483             0.000000   \n",
              "2                     0.0      0.000000             1.000000   \n",
              "3                     0.0    205.788017             0.083333   \n",
              "4                     0.0      0.000000             0.083333   \n",
              "\n",
              "   ONEOFF_PURCHASES_FREQUENCY  PURCHASES_INSTALLMENTS_FREQUENCY  \\\n",
              "0                    0.000000                          0.083333   \n",
              "1                    0.000000                          0.000000   \n",
              "2                    1.000000                          0.000000   \n",
              "3                    0.083333                          0.000000   \n",
              "4                    0.083333                          0.000000   \n",
              "\n",
              "   CASH_ADVANCE_FREQUENCY  CASH_ADVANCE_TRX  PURCHASES_TRX  CREDIT_LIMIT  \\\n",
              "0                0.000000                 0              2        1000.0   \n",
              "1                0.250000                 4              0        7000.0   \n",
              "2                0.000000                 0             12        7500.0   \n",
              "3                0.083333                 1              1        7500.0   \n",
              "4                0.000000                 0              1        1200.0   \n",
              "\n",
              "      PAYMENTS  MINIMUM_PAYMENTS  PRC_FULL_PAYMENT  TENURE  \n",
              "0   201.802084        139.509787          0.000000      12  \n",
              "1  4103.032597       1072.340217          0.222222      12  \n",
              "2   622.066742        627.284787          0.000000      12  \n",
              "3     0.000000               NaN          0.000000      12  \n",
              "4   678.334763        244.791237          0.000000      12  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# List files in the dataset directory to find the CSV file\n",
        "print(\"Files in dataset directory:\", os.listdir(path))\n",
        "\n",
        "# Replace 'CC_GENERAL.csv' with the actual filename if different\n",
        "csv_file = os.path.join(path, \"CC GENERAL.csv\")\n",
        "df = pd.read_csv(csv_file)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCp24MwK7Rw6",
        "outputId": "a0664e33-8696-41d8-cc79-d56d326fcd17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.DataFrame'>\n",
            "RangeIndex: 8950 entries, 0 to 8949\n",
            "Data columns (total 18 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   CUST_ID                           8950 non-null   str    \n",
            " 1   BALANCE                           8950 non-null   float64\n",
            " 2   BALANCE_FREQUENCY                 8950 non-null   float64\n",
            " 3   PURCHASES                         8950 non-null   float64\n",
            " 4   ONEOFF_PURCHASES                  8950 non-null   float64\n",
            " 5   INSTALLMENTS_PURCHASES            8950 non-null   float64\n",
            " 6   CASH_ADVANCE                      8950 non-null   float64\n",
            " 7   PURCHASES_FREQUENCY               8950 non-null   float64\n",
            " 8   ONEOFF_PURCHASES_FREQUENCY        8950 non-null   float64\n",
            " 9   PURCHASES_INSTALLMENTS_FREQUENCY  8950 non-null   float64\n",
            " 10  CASH_ADVANCE_FREQUENCY            8950 non-null   float64\n",
            " 11  CASH_ADVANCE_TRX                  8950 non-null   int64  \n",
            " 12  PURCHASES_TRX                     8950 non-null   int64  \n",
            " 13  CREDIT_LIMIT                      8949 non-null   float64\n",
            " 14  PAYMENTS                          8950 non-null   float64\n",
            " 15  MINIMUM_PAYMENTS                  8637 non-null   float64\n",
            " 16  PRC_FULL_PAYMENT                  8950 non-null   float64\n",
            " 17  TENURE                            8950 non-null   int64  \n",
            "dtypes: float64(14), int64(3), str(1)\n",
            "memory usage: 1.2 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D38YcsXQ7SZR",
        "outputId": "d92888fc-65bd-4752-9b54-38c6c06ff4fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BALANCE</th>\n",
              "      <th>BALANCE_FREQUENCY</th>\n",
              "      <th>PURCHASES</th>\n",
              "      <th>ONEOFF_PURCHASES</th>\n",
              "      <th>INSTALLMENTS_PURCHASES</th>\n",
              "      <th>CASH_ADVANCE</th>\n",
              "      <th>PURCHASES_FREQUENCY</th>\n",
              "      <th>ONEOFF_PURCHASES_FREQUENCY</th>\n",
              "      <th>PURCHASES_INSTALLMENTS_FREQUENCY</th>\n",
              "      <th>CASH_ADVANCE_FREQUENCY</th>\n",
              "      <th>CASH_ADVANCE_TRX</th>\n",
              "      <th>PURCHASES_TRX</th>\n",
              "      <th>CREDIT_LIMIT</th>\n",
              "      <th>PAYMENTS</th>\n",
              "      <th>MINIMUM_PAYMENTS</th>\n",
              "      <th>PRC_FULL_PAYMENT</th>\n",
              "      <th>TENURE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8949.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8637.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "      <td>8950.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1564.474828</td>\n",
              "      <td>0.877271</td>\n",
              "      <td>1003.204834</td>\n",
              "      <td>592.437371</td>\n",
              "      <td>411.067645</td>\n",
              "      <td>978.871112</td>\n",
              "      <td>0.490351</td>\n",
              "      <td>0.202458</td>\n",
              "      <td>0.364437</td>\n",
              "      <td>0.135144</td>\n",
              "      <td>3.248827</td>\n",
              "      <td>14.709832</td>\n",
              "      <td>4494.449450</td>\n",
              "      <td>1733.143852</td>\n",
              "      <td>864.206542</td>\n",
              "      <td>0.153715</td>\n",
              "      <td>11.517318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2081.531879</td>\n",
              "      <td>0.236904</td>\n",
              "      <td>2136.634782</td>\n",
              "      <td>1659.887917</td>\n",
              "      <td>904.338115</td>\n",
              "      <td>2097.163877</td>\n",
              "      <td>0.401371</td>\n",
              "      <td>0.298336</td>\n",
              "      <td>0.397448</td>\n",
              "      <td>0.200121</td>\n",
              "      <td>6.824647</td>\n",
              "      <td>24.857649</td>\n",
              "      <td>3638.815725</td>\n",
              "      <td>2895.063757</td>\n",
              "      <td>2372.446607</td>\n",
              "      <td>0.292499</td>\n",
              "      <td>1.338331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019163</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>128.281915</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>39.635000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1600.000000</td>\n",
              "      <td>383.276166</td>\n",
              "      <td>169.123707</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>873.385231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>361.280000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>856.901546</td>\n",
              "      <td>312.343947</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2054.140036</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1110.130000</td>\n",
              "      <td>577.405000</td>\n",
              "      <td>468.637500</td>\n",
              "      <td>1113.821139</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>6500.000000</td>\n",
              "      <td>1901.134317</td>\n",
              "      <td>825.485459</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>19043.138560</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>49039.570000</td>\n",
              "      <td>40761.250000</td>\n",
              "      <td>22500.000000</td>\n",
              "      <td>47137.211760</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>358.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>50721.483360</td>\n",
              "      <td>76406.207520</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            BALANCE  BALANCE_FREQUENCY     PURCHASES  ONEOFF_PURCHASES  \\\n",
              "count   8950.000000        8950.000000   8950.000000       8950.000000   \n",
              "mean    1564.474828           0.877271   1003.204834        592.437371   \n",
              "std     2081.531879           0.236904   2136.634782       1659.887917   \n",
              "min        0.000000           0.000000      0.000000          0.000000   \n",
              "25%      128.281915           0.888889     39.635000          0.000000   \n",
              "50%      873.385231           1.000000    361.280000         38.000000   \n",
              "75%     2054.140036           1.000000   1110.130000        577.405000   \n",
              "max    19043.138560           1.000000  49039.570000      40761.250000   \n",
              "\n",
              "       INSTALLMENTS_PURCHASES  CASH_ADVANCE  PURCHASES_FREQUENCY  \\\n",
              "count             8950.000000   8950.000000          8950.000000   \n",
              "mean               411.067645    978.871112             0.490351   \n",
              "std                904.338115   2097.163877             0.401371   \n",
              "min                  0.000000      0.000000             0.000000   \n",
              "25%                  0.000000      0.000000             0.083333   \n",
              "50%                 89.000000      0.000000             0.500000   \n",
              "75%                468.637500   1113.821139             0.916667   \n",
              "max              22500.000000  47137.211760             1.000000   \n",
              "\n",
              "       ONEOFF_PURCHASES_FREQUENCY  PURCHASES_INSTALLMENTS_FREQUENCY  \\\n",
              "count                 8950.000000                       8950.000000   \n",
              "mean                     0.202458                          0.364437   \n",
              "std                      0.298336                          0.397448   \n",
              "min                      0.000000                          0.000000   \n",
              "25%                      0.000000                          0.000000   \n",
              "50%                      0.083333                          0.166667   \n",
              "75%                      0.300000                          0.750000   \n",
              "max                      1.000000                          1.000000   \n",
              "\n",
              "       CASH_ADVANCE_FREQUENCY  CASH_ADVANCE_TRX  PURCHASES_TRX  CREDIT_LIMIT  \\\n",
              "count             8950.000000       8950.000000    8950.000000   8949.000000   \n",
              "mean                 0.135144          3.248827      14.709832   4494.449450   \n",
              "std                  0.200121          6.824647      24.857649   3638.815725   \n",
              "min                  0.000000          0.000000       0.000000     50.000000   \n",
              "25%                  0.000000          0.000000       1.000000   1600.000000   \n",
              "50%                  0.000000          0.000000       7.000000   3000.000000   \n",
              "75%                  0.222222          4.000000      17.000000   6500.000000   \n",
              "max                  1.500000        123.000000     358.000000  30000.000000   \n",
              "\n",
              "           PAYMENTS  MINIMUM_PAYMENTS  PRC_FULL_PAYMENT       TENURE  \n",
              "count   8950.000000       8637.000000       8950.000000  8950.000000  \n",
              "mean    1733.143852        864.206542          0.153715    11.517318  \n",
              "std     2895.063757       2372.446607          0.292499     1.338331  \n",
              "min        0.000000          0.019163          0.000000     6.000000  \n",
              "25%      383.276166        169.123707          0.000000    12.000000  \n",
              "50%      856.901546        312.343947          0.000000    12.000000  \n",
              "75%     1901.134317        825.485459          0.142857    12.000000  \n",
              "max    50721.483360      76406.207520          1.000000    12.000000  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GeXHUO97uYV",
        "outputId": "f50a7d04-83ce-4617-d450-1d6b12a0ee53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_51294/3996276063.py:8: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.\n",
            "\n",
            "See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html\n",
            "  X[\"CREDIT_LIMIT\"].fillna(X[\"CREDIT_LIMIT\"].median(), inplace=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0       1000.0\n",
              "1       7000.0\n",
              "2       7500.0\n",
              "3       7500.0\n",
              "4       1200.0\n",
              "         ...  \n",
              "8945    1000.0\n",
              "8946    1000.0\n",
              "8947    1000.0\n",
              "8948     500.0\n",
              "8949    1200.0\n",
              "Name: CREDIT_LIMIT, Length: 8950, dtype: float64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = df\n",
        "\n",
        "# dropped cust id as it is not a describing feature just an identifier for the\n",
        "# specific customer\n",
        "X = X.drop([\"CUST_ID\"], axis=1)\n",
        "\n",
        "# Its just one value lets just do median to get it\n",
        "X[\"CREDIT_LIMIT\"].fillna(X[\"CREDIT_LIMIT\"].median(), inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKpBAMBi_Ml3",
        "outputId": "32ebd48a-6832-4a8d-c834-b44f54af1c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BALANCE                               0\n",
            "BALANCE_FREQUENCY                     0\n",
            "PURCHASES                             0\n",
            "ONEOFF_PURCHASES                      0\n",
            "INSTALLMENTS_PURCHASES                0\n",
            "CASH_ADVANCE                          0\n",
            "PURCHASES_FREQUENCY                   0\n",
            "ONEOFF_PURCHASES_FREQUENCY            0\n",
            "PURCHASES_INSTALLMENTS_FREQUENCY      0\n",
            "CASH_ADVANCE_FREQUENCY                0\n",
            "CASH_ADVANCE_TRX                      0\n",
            "PURCHASES_TRX                         0\n",
            "CREDIT_LIMIT                          1\n",
            "PAYMENTS                              0\n",
            "MINIMUM_PAYMENTS                    313\n",
            "PRC_FULL_PAYMENT                      0\n",
            "TENURE                                0\n",
            "MIN_PAY_MISSING                       0\n",
            "dtype: int64\n",
            "BALANCE                             0.000000\n",
            "BALANCE_FREQUENCY                   0.000000\n",
            "PURCHASES                           0.000000\n",
            "ONEOFF_PURCHASES                    0.000000\n",
            "INSTALLMENTS_PURCHASES              0.000000\n",
            "CASH_ADVANCE                        0.000000\n",
            "PURCHASES_FREQUENCY                 0.000000\n",
            "ONEOFF_PURCHASES_FREQUENCY          0.000000\n",
            "PURCHASES_INSTALLMENTS_FREQUENCY    0.000000\n",
            "CASH_ADVANCE_FREQUENCY              0.000000\n",
            "CASH_ADVANCE_TRX                    0.000000\n",
            "PURCHASES_TRX                       0.000000\n",
            "CREDIT_LIMIT                        0.011173\n",
            "PAYMENTS                            0.000000\n",
            "MINIMUM_PAYMENTS                    3.497207\n",
            "PRC_FULL_PAYMENT                    0.000000\n",
            "TENURE                              0.000000\n",
            "MIN_PAY_MISSING                     0.000000\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_51294/2381676911.py:6: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.\n",
            "\n",
            "See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html\n",
            "  X[\"MINIMUM_PAYMENTS\"].fillna(X[\"MINIMUM_PAYMENTS\"].median(), inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# 313 missing values (~3.5%)\n",
        "# Financial behavior feature\n",
        "# Missingness is not random\n",
        "# This means missingness itself carries information.\n",
        "X[\"MIN_PAY_MISSING\"] = X[\"MINIMUM_PAYMENTS\"].isna().astype(int)\n",
        "X[\"MINIMUM_PAYMENTS\"].fillna(X[\"MINIMUM_PAYMENTS\"].median(), inplace=True)\n",
        "\n",
        "\n",
        "print(X.isna().sum())\n",
        "print((X.isna().sum() / len(X)) * 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBvQ_b4W-RI8",
        "outputId": "52e06d23-3500-472c-f42c-b0bb43c285dc"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'plotly'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m combinations\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_objects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgo\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'plotly'"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from itertools import combinations\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def generate_pca_report(n_components, df):\n",
        "    if n_components < 3:\n",
        "        raise ValueError(\"n_components must be >= 3 for 3D visualization\")\n",
        "\n",
        "    # ---- Preserve feature names\n",
        "    feature_names = df.columns\n",
        "\n",
        "    # ---- Scale\n",
        "    scaler = RobustScaler()\n",
        "    X_scaled = scaler.fit_transform(df)\n",
        "\n",
        "    # ---- PCA\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "    column_names = [f'PC{i+1}' for i in range(n_components)]\n",
        "    pca_df = pd.DataFrame(X_pca, columns=column_names)\n",
        "\n",
        "    # ---- 3D combinations\n",
        "    combos = list(combinations(column_names, 3))\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for i, (pc1, pc2, pc3) in enumerate(combos):\n",
        "        x = pca_df[pc1].values\n",
        "        y = pca_df[pc2].values\n",
        "        z = pca_df[pc3].values\n",
        "\n",
        "        # âœ… Distance from origin (depth)\n",
        "        distance = np.sqrt(x**2 + y**2 + z**2)\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Scatter3d(\n",
        "                x=x,\n",
        "                y=y,\n",
        "                z=z,\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                    size=2,\n",
        "                    color=distance,          # ðŸ‘ˆ DISTANCE-BASED COLOR\n",
        "                    colorscale='Turbo',\n",
        "                    opacity=0.75,\n",
        "                    showscale=True\n",
        "                ),\n",
        "                name=f'{pc1}-{pc2}-{pc3}',\n",
        "                visible=(i == 0)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # ---- Dropdown for PC combinations\n",
        "    buttons = []\n",
        "    for i, (pc1, pc2, pc3) in enumerate(combos):\n",
        "        visible = [False] * len(combos)\n",
        "        visible[i] = True\n",
        "        buttons.append(\n",
        "            dict(\n",
        "                label=f'{pc1}-{pc2}-{pc3}',\n",
        "                method='update',\n",
        "                args=[\n",
        "                    {'visible': visible},\n",
        "                    {'scene': {\n",
        "                        'xaxis': {'title': pc1},\n",
        "                        'yaxis': {'title': pc2},\n",
        "                        'zaxis': {'title': pc3}\n",
        "                    }}\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "    fig.update_layout(\n",
        "        updatemenus=[dict(\n",
        "            buttons=buttons,\n",
        "            direction=\"down\",\n",
        "            x=0.02,\n",
        "            y=1.1\n",
        "        )],\n",
        "        title=\"Interactive 3D PCA (Color = Distance from Origin)\",\n",
        "        scene=dict(\n",
        "            xaxis_title=combos[0][0],\n",
        "            yaxis_title=combos[0][1],\n",
        "            zaxis_title=combos[0][2],\n",
        "        )\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "    # ---- PCA Loadings\n",
        "    loadings_df = pd.DataFrame(\n",
        "        pca.components_.T,\n",
        "        columns=column_names,\n",
        "        index=feature_names\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        loadings_df,\n",
        "        cmap='RdBu_r',\n",
        "        center=0,\n",
        "        annot=True\n",
        "    )\n",
        "    plt.title(\"PCA Loading Scores\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ---- Explained variance\n",
        "    print(\"\\nExplained Variance Ratio:\")\n",
        "    for i, var in enumerate(pca.explained_variance_ratio_, 1):\n",
        "        print(f\"PC{i}: {var:.4f} ({var*100:.2f}%)\")\n",
        "\n",
        "    print(f\"\\nCumulative Variance: {pca.explained_variance_ratio_.sum():.2%}\")\n",
        "    return pca_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0NFpjK9-u_e"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_pca_scree_plot(X):\n",
        "  import matplotlib.pyplot as plt\n",
        "  from sklearn.decomposition import PCA\n",
        "\n",
        "  from sklearn.preprocessing import RobustScaler\n",
        "  scaler = RobustScaler()\n",
        "  X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "  # Fit PCA with all components\n",
        "  pca_full = PCA()\n",
        "  pca_full.fit(X_scaled)\n",
        "\n",
        "  explained_variance = pca_full.explained_variance_ratio_\n",
        "  cumulative_variance = explained_variance.cumsum()\n",
        "\n",
        "  # Scree (elbow) plot\n",
        "  plt.figure()\n",
        "  plt.plot(\n",
        "      range(1, len(explained_variance) + 1),\n",
        "      explained_variance,\n",
        "      marker='o'\n",
        "  )\n",
        "  plt.xlabel(\"Number of Principal Components\")\n",
        "  plt.ylabel(\"Explained Variance Ratio\")\n",
        "  plt.title(\"PCA Scree Plot (Elbow Method)\")\n",
        "  plt.show()\n",
        "\n",
        "  # Optional but useful: cumulative variance plot\n",
        "  plt.figure()\n",
        "  plt.plot(\n",
        "      range(1, len(cumulative_variance) + 1),\n",
        "      cumulative_variance,\n",
        "      marker='o'\n",
        "  )\n",
        "  plt.xlabel(\"Number of Principal Components\")\n",
        "  plt.ylabel(\"Cumulative Explained Variance\")\n",
        "  plt.title(\"Cumulative Explained Variance\")\n",
        "  plt.axhline(y=0.8, linestyle='--')  # common cutoff\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RHAgVknDxsq"
      },
      "outputs": [],
      "source": [
        "def show_corr_graph_df(X):\n",
        "  import seaborn as sns\n",
        "\n",
        "  corr = X.corr()\n",
        "  plt.figure(figsize=(12,8))\n",
        "  sns.heatmap(corr, annot=True, fmt=\".2f\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O52hzjzz_cVu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "X.hist(bins=30, figsize=(20,15))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUP33KUSOV6v"
      },
      "outputs": [],
      "source": [
        "# Check variance\n",
        "print(f\"TENURE variance: {X['TENURE'].var():.2f}\")\n",
        "print(f\"TENURE unique values: {X['TENURE'].nunique()}\")\n",
        "print(f\"% with TENURE=12: {(X['TENURE']==12).sum()/len(X)*100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paHFjtZjOZft"
      },
      "outputs": [],
      "source": [
        "# Tenure is overloaded with 12 so it is not that useful because it does not give much information so lets remove it\n",
        "\n",
        "X = X.drop([\"TENURE\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1oHNPWgSsHX"
      },
      "outputs": [],
      "source": [
        "for col in X.select_dtypes(include=[\"int64\", \"object\"]):\n",
        "    print(col, X[col].nunique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iE4Nm9kcz3q"
      },
      "outputs": [],
      "source": [
        "create_pca_scree_plot(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7qIxp00A4nc"
      },
      "source": [
        "# Initial Observation of the Raw Data\n",
        "\n",
        "Exploratory analysis of the dataset revealed that the majority of monetary variables (e.g., BALANCE, PURCHASES, CASH_ADVANCE, PAYMENTS, CREDIT_LIMIT) exhibited severely right-skewed distributions with long tails. Most customers had relatively small values, while a small subset showed extremely large magnitudes.\n",
        "\n",
        "Additionally, several frequency-based features were bounded between 0 and 1 and displayed heavy concentration at boundary values (particularly 0 and 1), indicating categorical-like behavioral patterns rather than continuous numerical variation.\n",
        "\n",
        "This distributional imbalance posed a significant problem for distance-based clustering algorithms.\n",
        "\n",
        "# Problem With Using Raw Features for Clustering\n",
        "\n",
        "Clustering algorithms such as K-Means rely on Euclidean distance, which is highly sensitive to feature scale and magnitude. In the raw data:\n",
        "\n",
        "Features with large numeric ranges dominated distance calculations\n",
        "\n",
        "Customers with extreme monetary values disproportionately influenced cluster centroidsProblem With Using Raw Features for Clustering\n",
        "\n",
        "Clustering algorithms such as K-Means rely on Euclidean distance, which is highly sensitive to feature scale and magnitude. In the raw data:\n",
        "\n",
        "- Features with large numeric ranges dominated distance calculations\n",
        "\n",
        "- Customers with extreme monetary values disproportionately influenced cluster centroids\n",
        "\n",
        "- Customers with moderate or low spending behavior collapsed into indistinguishable groups\n",
        "\n",
        "As a result, clustering on the raw data would primarily separate customers by spending volume, rather than by meaningful behavioral patterns.\n",
        "\n",
        "Customers with moderate or low spending behavior collapsed into indistinguishable groups\n",
        "\n",
        "As a result, clustering on the raw data would primarily separate customers by spending volume, rather than by meaningful behavioral patterns.\n",
        "\n",
        "# Log Transformation of Monetary Features\n",
        "\n",
        "To address the extreme skewness and reduce the influence of outliers, a logarithmic transformation was applied to monetary features using the log1p function.\n",
        "\n",
        "Rationale:\n",
        "\n",
        "- Compresses long right tails while preserving relative ordering\n",
        "\n",
        "- Reduces dominance of extreme values without discarding data\n",
        "\n",
        "- Stabilizes variance across customers\n",
        "\n",
        "Observed Effect:\n",
        "After log transformation, previously heavy-tailed distributions became more symmetric and spread more evenly across their range. This improved the ability of distance-based methods to disti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCjgk_sK-FTF"
      },
      "outputs": [],
      "source": [
        "log_cols = [\n",
        "    \"BALANCE\",\n",
        "    \"PAYMENTS\",\n",
        "    \"MINIMUM_PAYMENTS\",\n",
        "    \"CREDIT_LIMIT\",\n",
        "]\n",
        "\n",
        "import numpy as np\n",
        "X[log_cols] = X[log_cols].apply(np.log1p)\n",
        "\n",
        "# check for negative values\n",
        "(X[log_cols] < 0).sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJXVWtlf-0dR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jnv-wryo-bCk"
      },
      "outputs": [],
      "source": [
        "X.hist(bins=30, figsize=(20,15))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGHO01N9bfro"
      },
      "outputs": [],
      "source": [
        "create_pca_scree_plot(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIyz3jRXNk28"
      },
      "source": [
        "After doing log transformation on all features we found better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn2oiFO3RSM2"
      },
      "source": [
        "# Preprocessing Justification: Handling Zero-Inflated Cash Advance Features\n",
        "\n",
        "## Problem Identified\n",
        "The cash advance features (CASH_ADVANCE, CASH_ADVANCE_FREQUENCY, CASH_ADVANCE_TRX) exhibit severe zero-inflation, with approximately 75% of customers showing zero values. This bimodal distribution (zero vs. non-zero) causes two critical issues for clustering:\n",
        "\n",
        "1. **Distance metric distortion**: Euclidean distance calculations become dominated by the binary pattern of \"uses vs. doesn't use\" rather than capturing nuanced behavioral differences\n",
        "2. **Feature redundancy**: Three variables measure overlapping aspects of the same behavior (cash advance usage), leading to multicollinearity and over-weighting this single dimension\n",
        "\n",
        "## Solution Applied\n",
        "We engineer three complementary features that capture distinct aspects of cash advance behavior:\n",
        "\n",
        "### 1. Binary Indicator (`uses_cash_advance`)\n",
        "```python\n",
        "uses_cash_advance = (CASH_ADVANCE > 0).astype(int)\n",
        "```\n",
        "- Captures the primary behavioral split: cash advance users vs. non-users\n",
        "- Provides clear cluster interpretability\n",
        "\n",
        "### 2. Economic Magnitude (`cash_advance_amount_log`)\n",
        "```python\n",
        "cash_advance_amount_log = log1p(CASH_ADVANCE)\n",
        "```\n",
        "- Captures the monetary value of cash advance usage\n",
        "- Log transformation normalizes the right-skewed distribution\n",
        "- Preserves zero values (log1p(0) = 0)\n",
        "\n",
        "### 3. Behavioral Pattern (`cash_advance_frequency`)\n",
        "```python\n",
        "cash_advance_frequency = CASH_ADVANCE_FREQUENCY  # Retained as-is\n",
        "```\n",
        "- Captures usage frequency (already normalized 0-1)\n",
        "- Distinguishes one-time large withdrawals from frequent small withdrawals\n",
        "- Reveals chronic vs. emergency usage patterns\n",
        "\n",
        "### Features Dropped\n",
        "- **CASH_ADVANCE** â†’ Replaced by log-transformed version\n",
        "- **CASH_ADVANCE_TRX** â†’ Redundant given amount and frequency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-fLz42gFfpG"
      },
      "outputs": [],
      "source": [
        "X['uses_cash_advance'] = (X['CASH_ADVANCE'] > 0).astype(int)\n",
        "X['cash_advance_log'] = np.log1p(X['CASH_ADVANCE'])\n",
        "X['cash_advance_frequency'] = X['CASH_ADVANCE_FREQUENCY']\n",
        "X = X.drop(['CASH_ADVANCE_FREQUENCY', 'CASH_ADVANCE_TRX', 'CASH_ADVANCE'], axis=1)\n",
        "X[['uses_cash_advance', 'cash_advance_log', 'cash_advance_frequency']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWNDEDm2nGrp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns-M1aLnOztz"
      },
      "outputs": [],
      "source": [
        "X[['uses_cash_advance', 'cash_advance_log', 'cash_advance_frequency']].hist(bins=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx7MyqHbSr50"
      },
      "outputs": [],
      "source": [
        "print(\"Cash Advance Usage Distribution:\")\n",
        "print(X['uses_cash_advance'].value_counts().sort_index())\n",
        "print()\n",
        "\n",
        "# With percentages\n",
        "print(\"Cash Advance Usage Distribution (with percentages):\")\n",
        "print(X['uses_cash_advance'].value_counts(normalize=True).sort_index() * 100)\n",
        "print()\n",
        "\n",
        "# More detailed breakdown\n",
        "print(\"\\nDetailed Summary:\")\n",
        "print(f\"Non-users (0): {(X['uses_cash_advance'] == 0).sum()} customers ({(X['uses_cash_advance'] == 0).sum() / len(X) * 100:.1f}%)\")\n",
        "print(f\"Users (1): {(X['uses_cash_advance'] == 1).sum()} customers ({(X['uses_cash_advance'] == 1).sum() / len(X) * 100:.1f}%)\")\n",
        "print(f\"Total: {len(X)} customers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXmogngASB-s"
      },
      "source": [
        "\n",
        "## Results of Cash Advance Feature Engineering\n",
        "\n",
        "### Transformed Distributions\n",
        "\n",
        "**`uses_cash_advance` (Binary Indicator)**\n",
        "- Clean binary split: 4,628 non-users (0) vs. 4,322 users (1)\n",
        "- 48.3% of customers use cash advances\n",
        "\n",
        "**`cash_advance_amount_log` (Log-Transformed Amount)**\n",
        "- Preserves zero spike for non-users (~4,628)\n",
        "- Users show smooth distribution from 2.5 to 10.0\n",
        "- Successfully normalizes extreme values while maintaining economic magnitude distinctions\n",
        "\n",
        "**`cash_advance_frequency` (Retained)**\n",
        "- Ranges from 0 (non-users) to 1 (use in every billing cycle)\n",
        "- Among users: distinguishes sporadic vs. frequent usage patterns\n",
        "\n",
        "## Key Improvements\n",
        "\n",
        "1. **Eliminated redundancy**: Three correlated features â†’ three orthogonal dimensions\n",
        "2. **Balanced information**: Binary flag (user type) + continuous amount (magnitude) + frequency (pattern)\n",
        "3. **Enhanced separability**: Non-users form distinct group; users differentiate by both economic impact and behavioral frequency\n",
        "4. **Prevents zero-inflation dominance**: Clustering can now capture nuanced behavior beyond simple \"uses vs. doesn't use\"\n",
        "5. **Preserves behavioral nuance**: Frequency enables distinction between emergency borrowers (high amount, low frequency) and chronic users (moderate amount, high frequency)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0uK6kzRO3NG"
      },
      "outputs": [],
      "source": [
        "# same as above\n",
        "\n",
        "X['uses_installments'] = (X['INSTALLMENTS_PURCHASES'] > 0).astype(int)\n",
        "X['installments_amount_log'] = np.log1p(X['INSTALLMENTS_PURCHASES'])\n",
        "X = X.drop(['INSTALLMENTS_PURCHASES'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZShX8BRwkBIm"
      },
      "outputs": [],
      "source": [
        "X['uses_oneoff'] = (X['ONEOFF_PURCHASES'] > 0).astype(int)\n",
        "X['oneoff_amount_log'] = np.log1p(X['ONEOFF_PURCHASES'])\n",
        "X = X.drop(['ONEOFF_PURCHASES'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_vlMpbOkOhV"
      },
      "outputs": [],
      "source": [
        "# Keep balance frequency as its an indicator of activity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWse1vZRkSf8"
      },
      "outputs": [],
      "source": [
        "# Purchase frequency captures important behaviors for non buyers vs frequent buyers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1J55EOvikdxt"
      },
      "outputs": [],
      "source": [
        "X[\"uses_purchase\"] = (X['PURCHASES'] > 0).astype(int)\n",
        "X['purchases_log'] = np.log1p(X['PURCHASES'])\n",
        "X['purchase_frequency'] = X['PURCHASES_FREQUENCY']\n",
        "X['purchases_trx_log'] = np.log1p(X['PURCHASES_TRX'])\n",
        "X = X.drop(['PURCHASES', \"PURCHASES_FREQUENCY\", 'PURCHASES_TRX'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-mJwhLBbc10"
      },
      "outputs": [],
      "source": [
        "create_pca_scree_plot(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc0Dd0h1l7_M"
      },
      "outputs": [],
      "source": [
        "X.hist(bins=30, figsize=(20,15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1bxbjCuUNXP"
      },
      "outputs": [],
      "source": [
        "show_corr_graph_df(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z3dsQGTZ0oe"
      },
      "source": [
        "I removed highly correlated behavioral proxies to avoid overweighting the same customer actions multiple times in distance-based clustering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djerUP_mZ3N2"
      },
      "outputs": [],
      "source": [
        "X = X.drop([\"uses_cash_advance\",\n",
        "            \"cash_advance_frequency\",\n",
        "            \"uses_installments\",\n",
        "            \"uses_oneoff\",\n",
        "            \"purchases_trx_log\",\n",
        "            \"uses_purchase\",\n",
        "            \"PURCHASES_INSTALLMENTS_FREQUENCY\",\n",
        "            ], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eT11ZlmRPblI"
      },
      "outputs": [],
      "source": [
        "X.hist(bins=30, figsize=(20,15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYh9H9swaZPP"
      },
      "outputs": [],
      "source": [
        "show_corr_graph_df(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjsDpaHnl8dc"
      },
      "outputs": [],
      "source": [
        "create_pca_scree_plot(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJI7esUt7Y-P"
      },
      "outputs": [],
      "source": [
        "generate_pca_report(6, X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImFpv7pW-Z7G"
      },
      "outputs": [],
      "source": [
        "pca_df = generate_pca_report(4, X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnF_2nbwtoQ1"
      },
      "source": [
        "# Principal Component Analysis (PCA) Interpretation and Component Selection\n",
        "\n",
        "We performed Principal Component Analysis (PCA) using two configurations: **4 principal components (PCs)** and **6 principal components**, explaining **88.28%** and **95.23%** of the total variance respectively. This section provides a detailed interpretation of the extracted components and justifies the selection of **4 PCs for downstream analysis**.\n",
        "\n",
        "---\n",
        "\n",
        "## Interpretation of Principal Components (4-PC Solution)\n",
        "\n",
        "### PC1 â€“ Credit Utilization & Balance Behavior\n",
        "**Key loadings**\n",
        "- BALANCE_FREQUENCY (â‰ˆ +0.81)\n",
        "- BALANCE (â‰ˆ +0.26)\n",
        "- MINIMUM_PAYMENTS (â‰ˆ +0.20)\n",
        "- PRC_FULL_PAYMENT (â‰ˆ âˆ’0.45)\n",
        "\n",
        "**Explanation**  \n",
        "PC1 captures how frequently customers carry outstanding balances versus paying in full. High PC1 scores correspond to customers who regularly revolve balances and rely on minimum payments, while low scores indicate disciplined users who consistently pay in full. This component represents the primary axis of credit usage intensity.\n",
        "\n",
        "---\n",
        "\n",
        "### PC2 â€“ Payment Discipline\n",
        "**Key loadings**\n",
        "- PRC_FULL_PAYMENT (â‰ˆ +0.82)\n",
        "- BALANCE_FREQUENCY (â‰ˆ +0.42)\n",
        "\n",
        "**Explanation**  \n",
        "PC2 reflects repayment reliability independent of spending volume. Customers with high scores consistently pay their balances in full, whereas lower scores indicate partial or inconsistent repayment behavior. This component isolates payment discipline as a distinct behavioral dimension.\n",
        "\n",
        "---\n",
        "\n",
        "### PC3 â€“ Spending Structure and Purchase Behavior\n",
        "**Key loadings**\n",
        "- ONEOFF_PURCHASES_FREQUENCY (â‰ˆ +0.59)\n",
        "- purchases_log (â‰ˆ +0.52)\n",
        "- oneoff_amount_log (â‰ˆ +0.32)\n",
        "- purchase_frequency (â‰ˆ +0.20)\n",
        "\n",
        "**Explanation**  \n",
        "PC3 represents how customers spend, distinguishing between frequent purchases and one-off, higher-value transactions. This component captures consumption and transaction patterns rather than repayment or balance management behavior.\n",
        "\n",
        "---\n",
        "\n",
        "### PC4 â€“ Repayment Pressure and Liquidity Stress\n",
        "**Key loadings**\n",
        "- PAYMENTS (â‰ˆ +0.72)\n",
        "- MINIMUM_PAYMENTS (â‰ˆ +0.31)\n",
        "- BALANCE (â‰ˆ +0.29)\n",
        "- cash_advance_log (â‰ˆ +0.26)\n",
        "\n",
        "**Explanation**  \n",
        "PC4 reflects financial strain and liquidity pressure. Higher scores indicate customers making larger payments, holding higher balances, and relying more on cash advances, suggesting increased repayment burden or short-term liquidity needs.\n",
        "\n",
        "---\n",
        "\n",
        "## Interpretation of Additional Components (6-PC Solution)\n",
        "\n",
        "Extending the PCA to **6 components** increases the explained variance to **95.23%**, but the additional components provide limited new behavioral insight.\n",
        "\n",
        "---\n",
        "\n",
        "### PC5 â€“ Installment vs One-Off Spending Contrast\n",
        "**Key loadings**\n",
        "- installments_amount_log (â‰ˆ âˆ’0.42)\n",
        "- purchases_log (â‰ˆ âˆ’0.42)\n",
        "- ONEOFF_PURCHASES_FREQUENCY (â‰ˆ +0.63)\n",
        "\n",
        "**Explanation**  \n",
        "PC5 contrasts installment-heavy spending with direct or one-off purchases. While this component adds granularity to spending behavior, it does not introduce a fundamentally new behavioral dimension beyond what is already captured by PC3.\n",
        "\n",
        "---\n",
        "\n",
        "### PC6 â€“ Minimum Payment Dominance\n",
        "**Key loadings**\n",
        "- MINIMUM_PAYMENTS (â‰ˆ +0.72)\n",
        "- Secondary contributions from PAYMENTS and CREDIT_LIMIT\n",
        "\n",
        "**Explanation**  \n",
        "PC6 is largely driven by a single variable, indicating that the PCA is capturing residual variance rather than meaningful latent structure. Components dominated by a single feature are generally unstable and offer limited interpretive value.\n",
        "\n",
        "---\n",
        "\n",
        "## Justification for Selecting 4 PCs\n",
        "\n",
        "### Variance Coverage\n",
        "- 4 PCs explain **88.28%** of total variance\n",
        "- 6 PCs explain **95.23%**, adding only ~7% additional variance\n",
        "\n",
        "The majority of meaningful structure is already captured within the first four components.\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretability and Behavioral Coverage\n",
        "The 4-PC solution cleanly represents four distinct and interpretable behavioral dimensions:\n",
        "1. Credit utilization intensity  \n",
        "2. Payment discipline  \n",
        "3. Spending patterns  \n",
        "4. Financial strain  \n",
        "\n",
        "Additional components mainly refine existing patterns rather than reveal new structure.\n",
        "\n",
        "---\n",
        "\n",
        "### Model Simplicity and Stability\n",
        "Using fewer components reduces dimensionality, limits noise, and improves model stability and generalization in downstream tasks such as clustering or predictive modeling.\n",
        "\n",
        "---\n",
        "\n",
        "## Final Justification Statement\n",
        "\n",
        "Although the 6-component PCA explains a higher proportion of total variance, the additional components primarily capture marginal or redundant patterns. The 4-component solution, explaining 88.28% of the variance, retains the key behavioral dimensions of credit usage, payment discipline, spending behavior, and financial strain, providing a more interpretable and robust representation for downstream analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdzyeNGFBNYP"
      },
      "source": [
        "# Scaling of Features Using RobustScaler\n",
        "\n",
        "After log transformation, features were scaled using RobustScaler, which normalizes data based on the median and interquartile range.\n",
        "\n",
        "Rationale:\n",
        "\n",
        "- Ensures all features contribute comparably to distance calculations\n",
        "\n",
        "- Prevents residual outliers from disproportionately influencing clusters\n",
        "\n",
        "- More appropriate than standard scaling for non-Gaussian data\n",
        "\n",
        "Observed Effect:\n",
        "Scaling aligned features onto a comparable numeric range without reintroducing sensitivity to extreme values, allowing clustering algorithms to weigh behavioral and monetary features more evenly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SxGZBSyEr5I"
      },
      "outputs": [],
      "source": [
        "pc_names = {\n",
        "    \"PC1\": \"Credit Utilization Intensity\",\n",
        "    \"PC2\": \"Payment Discipline\",\n",
        "    \"PC3\": \"Spending Pattern\",\n",
        "    \"PC4\": \"Financial Strain\"\n",
        "}\n",
        "\n",
        "pca_df = pca_df.rename(columns=pc_names)\n",
        "pca_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGnw8keLyRxg"
      },
      "source": [
        "# Clustering Method Selection and Justification\n",
        "\n",
        "## Objective\n",
        "The goal of this analysis is to identify meaningful patterns in **credit card utilization behavior** by clustering individuals based on latent behavioral dimensions derived from PCA. These clusters are intended to represent distinct financial behavior profiles rather than artificially separated geometric groupings.\n",
        "\n",
        "---\n",
        "\n",
        "## Feature Representation\n",
        "\n",
        "After preprocessing and dimensionality reduction, the data is represented using four principal components:\n",
        "\n",
        "- **PC1 â€“ Credit Utilization Intensity**  \n",
        "- **PC2 â€“ Payment Discipline**  \n",
        "- **PC3 â€“ Spending Pattern**  \n",
        "- **PC4 â€“ Financial Strain**\n",
        "\n",
        "These components capture the dominant behavioral axes of credit card usage and are used as inputs to the clustering algorithms.\n",
        "\n",
        "---\n",
        "\n",
        "## Observations After PCA\n",
        "\n",
        "Visual inspection of the PCA-transformed space shows:\n",
        "- No clear spherical or compact clusters\n",
        "- Points are broadly distributed, forming a near-uniform or â€œcube-likeâ€ structure\n",
        "- Significant overlap between behavioral patterns is expected, especially for users with moderate credit behavior\n",
        "\n",
        "These observations strongly influence algorithm selection.\n",
        "\n",
        "---\n",
        "\n",
        "## Considered Clustering Algorithms\n",
        "\n",
        "### 1. K-Means Clustering (Not Selected as Primary)\n",
        "\n",
        "**Rationale for consideration**:\n",
        "- Simple and widely used\n",
        "- Operates based on distances between points\n",
        "- Can segment users based on relative position in feature space\n",
        "\n",
        "**Limitations in this context**:\n",
        "- Assumes spherical, equally sized clusters\n",
        "- Requires pre-specifying the number of clusters\n",
        "- Sensitive to outliers\n",
        "- Poor fit for overlapping and irregular behavioral patterns\n",
        "\n",
        "**Conclusion**:  \n",
        "K-means was explored during the exploratory phase but was **not selected as the primary method** due to the absence of spherical cluster structure and the presence of overlapping behaviors. Its assumptions do not align well with the observed data geometry.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Hierarchical Clustering (Support\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Hierarchical Clustering (Supporting Analysis)\n",
        "\n",
        "**Why it is suitable**:\n",
        "- Does not require specifying the number of clusters upfront\n",
        "- Captures hierarchical relationships between observations\n",
        "- Useful for analyzing how behavioral patterns split at different similarity levels\n",
        "\n",
        "**Relevance to this study**:\n",
        "- PCA components represent related financial behaviors\n",
        "- Hierarchical clustering allows inspection of nested groupings (e.g., disciplined vs. undisciplined users, then further subgroups)\n",
        "\n",
        "**Role in the analysis**:\n",
        "- Used to **explore structure and validate relationships**\n",
        "- Dendrograms aid interpretability\n",
        "- Not used as the final clustering method due to scalability and sensitivity to linkage choices\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Density-Based Clustering (DBSCAN / HDBSCAN)\n",
        "\n",
        "**Why this is appropriate**:\n",
        "- Does not assume spherical cluster shapes\n",
        "- Can identify clusters of arbitrary geometry\n",
        "- Explicitly models noise and outliers\n",
        "- Does not require pre-defining the number of clusters\n",
        "\n",
        "**Relevance to credit behavior data**:\n",
        "- Financial behaviors often form dense regions with gradual transitions\n",
        "- Users with extreme utilization or financial strain naturally appear as outliers\n",
        "- The cube-like distribution suggests density variation rather than clear centroids\n",
        "\n",
        "**Conclusion**:  \n",
        "Density-based clustering is well-suited for uncovering **irregular, behavior-driven groupings** and identifying atypical users.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Gaussian Mixture Models (GMM)\n",
        "\n",
        "**Why this is appropriate**:\n",
        "- Models clusters as probability distributions\n",
        "- Allows **overlapping clusters**\n",
        "- Provides soft assignments (membership probabilities)\n",
        "\n",
        "**Relevance to this study**:\n",
        "- Credit behaviors are not strictly separable\n",
        "- Users in transitional financial states (e.g., improving or deteriorating discipline) are expected\n",
        "- GMM captures uncertainty in cluster membership\n",
        "\n",
        "**Conclusion**:  \n",
        "GMM is particularly suitable for representing **continuous and overlapping financial behavior segments**, which aligns with real-world credit usage patterns.\n",
        "\n",
        "---\n",
        "\n",
        "## Final Methodological Choice\n",
        "\n",
        "- **Primary methods**:  \n",
        "  - Density-Based Clustering (DBSCAN or HDBSCAN)  \n",
        "  - Gaussian Mixture Models (GMM)\n",
        "\n",
        "- **Supporting analysis**:  \n",
        "  - Hierarchical clustering for structural validation\n",
        "\n",
        "- **Exploratory only**:  \n",
        "  - K-means (not used for final segmentation)\n",
        "\n",
        "This combination balances:\n",
        "- Flexibility in cluster shape\n",
        "- Ability to model overlapK-means was explored during the exploratory phase but was not selected as the primary method due to the absence of spherical cluster structure and the presence of overlapping behaviors. Its assumptions do not align well with the observed data geometry.\n",
        "- Interpretability\n",
        "- Alignment with domain expectations\n",
        "\n",
        "---\n",
        "\n",
        "## Cluster Validation and Interpretation\n",
        "\n",
        "Clusters are evaluated using:\n",
        "- Internal validation metrics (e.g., silhouette score, Daviesâ€“Bouldin index)\n",
        "- Stability analysis across random seeds and subsampling\n",
        "- Behavioral interpretability using feature distributions per cluster\n",
        "\n",
        "Each resulting cluster is characterized in terms of:\n",
        "- Credit utilization intensity\n",
        "- Payment discipline\n",
        "- Spending behavior\n",
        "- Financial strain profile\n",
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "The selected clustering approaches reflect both the **statistical structure of the data** and the **real-world complexity of financial behavior**. Rather than enforcing artificial separation, the methodology prioritizes interpretability, robustness, and domain relevance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te2LKDI3uhOY"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "number_of_features = 4\n",
        "min_samples = 2 * number_of_features\n",
        "\n",
        "\n",
        "k = min_samples\n",
        "\n",
        "nn = NearestNeighbors(n_neighbors=k)\n",
        "nn.fit(pca_df)\n",
        "\n",
        "distances, _ = nn.kneighbors(pca_df)\n",
        "k_distances = np.sort(distances[:, k-1])\n",
        "\n",
        "plt.plot(k_distances)\n",
        "plt.ylabel(f\"{k}-NN distance\")\n",
        "plt.xlabel(\"Points sorted by distance\")\n",
        "plt.show()\n",
        "\n",
        "y = k_distances\n",
        "x = np.arange(len(y))\n",
        "p1 = np.array([x[0], y[0]])\n",
        "p2 = np.array([x[-1], y[-1]])\n",
        "\n",
        "distances = np.abs(\n",
        "    np.cross(p2 - p1, p1 - np.vstack((x, y)).T)\n",
        ") / np.linalg.norm(p2 - p1)\n",
        "\n",
        "elbow_index = np.argmax(distances)\n",
        "optimal_eps = y[elbow_index]\n",
        "\n",
        "print(\"Min Samples based on dimentionality rule of thumb:\", min_samples)\n",
        "print(\"Optimal eps:\", optimal_eps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngxaQiAf3wsa"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "optimal_eps=0.3\n",
        "min_smples=8\n",
        "db = DBSCAN(eps=optimal_eps, min_samples=min_samples, metric=\"euclidean\")\n",
        "db.fit(pca_df)\n",
        "labels = db.labels_\n",
        "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "print(f\"clusters={n_clusters}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xrlnphhy6L0r"
      },
      "outputs": [],
      "source": [
        "def generate_3d_cluster_report(df, labels):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import plotly.graph_objects as go\n",
        "    from itertools import combinations\n",
        "\n",
        "    # ---- Validation\n",
        "    if df.shape[1] < 3:\n",
        "        raise ValueError(\"Dataset must have at least 3 features\")\n",
        "\n",
        "    if len(df) != len(labels):\n",
        "        raise ValueError(\"df and labels must have the same length\")\n",
        "\n",
        "    # ---- Ensure labels are 1D\n",
        "    if isinstance(labels, pd.DataFrame):\n",
        "        labels = labels.iloc[:, 0]\n",
        "    labels = np.asarray(labels)\n",
        "\n",
        "    feature_names = df.columns\n",
        "    combos = list(combinations(feature_names, 3))\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for i, (f1, f2, f3) in enumerate(combos):\n",
        "        fig.add_trace(\n",
        "            go.Scatter3d(\n",
        "                x=df[f1],\n",
        "                y=df[f2],\n",
        "                z=df[f3],\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                    size=3,\n",
        "                    color=labels,          # ðŸ‘ˆ CLUSTER LABELS\n",
        "                    colorscale='Turbo',\n",
        "                    opacity=0.8,\n",
        "                    showscale=True,\n",
        "                    colorbar=dict(title=\"Cluster\")\n",
        "                ),\n",
        "                name=f\"{f1}-{f2}-{f3}\",\n",
        "                visible=(i == 0)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # ---- Dropdown\n",
        "    buttons = []\n",
        "    for i, (f1, f2, f3) in enumerate(combos):\n",
        "        visible = [False] * len(combos)\n",
        "        visible[i] = True\n",
        "        buttons.append(\n",
        "            dict(\n",
        "                label=f\"{f1}-{f2}-{f3}\",\n",
        "                method=\"update\",\n",
        "                args=[\n",
        "                    {\"visible\": visible},\n",
        "                    {\"scene\": {\n",
        "                        \"xaxis\": {\"title\": f1},\n",
        "                        \"yaxis\": {\"title\": f2},\n",
        "                        \"zaxis\": {\"title\": f3}\n",
        "                    }}\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"Interactive 3D Feature Space (Colored by Cluster Labels)\",\n",
        "        updatemenus=[dict(\n",
        "            buttons=buttons,\n",
        "            direction=\"down\",\n",
        "            x=1,\n",
        "            y=2\n",
        "        )],\n",
        "        scene=dict(\n",
        "            xaxis_title=combos[0][0],\n",
        "            yaxis_title=combos[0][1],\n",
        "            zaxis_title=combos[0][2]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf7W7H2K5BWS"
      },
      "outputs": [],
      "source": [
        "generate_3d_cluster_report(df=pca_df, labels=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgbUwGj85PLu"
      },
      "outputs": [],
      "source": [
        "pd.Series(labels).value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb-Bjktr7mhC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "venv (3.13.11)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}